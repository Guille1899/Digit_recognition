{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digit classifier with LeNet-5\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "This notebook allows you to recognize digits (i.e., numbers from 0 to 9) manually drawn on your screen.\n",
    "\n",
    "## LeNet-5\n",
    "\n",
    "Convolutional Neural Networks is the standard architecture of a neural network designed for solving tasks associated with images (e.g., image classification). Some of the well-known deep learning architectures for CNN are LeNet-5 (7 layers), GoogLeNet (22 layers), AlexNet (8 layers), VGG (16â€“19 layers), and ResNet (152 layers). \n",
    "\n",
    "For this project, we use LeNet-5, which has been successfully used on the MNIST dataset to identify handwritten-digit patterns. The LeNet-5 architecture is represented in the following image.\n",
    "\n",
    "![screenshot](img/lenet.png)\n",
    "\n",
    "## Data\n",
    "\n",
    "The dataset used to train, validate and test the model, correpsond to the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. \n",
    "It is composed by a training set of 60,000 examples, and a test set of 10,000 examples. \n",
    "The digits have been pre-processed to be size-normalized and centered in a fixed-size image of 28x28 pixels.\n",
    "\n",
    "![screenshot](img/mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np ; np.random.seed(1) # for reproducibility\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.0\n",
      "The GPU will be used for calculations.\n"
     ]
    }
   ],
   "source": [
    "# Indicate the version of Tensorflow and whether it uses the CPU or the GPU\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print(\"The GPU will be used for calculations.\")\n",
    "    \n",
    "else:\n",
    "    print(\"The CPU will be used for calculations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(OS, url, distination_path):\n",
    "    \n",
    "    ''' Download data from an URL and save it locally '''\n",
    "    \n",
    "    # Import dataset\n",
    "    try:\n",
    "        if OS == 'macOS' or OS == 'Linux':\n",
    "            os.system(\"!wget --no-check-certificate \" + url + \" -O \" + distination_path)\n",
    "        elif OS == 'Windows':\n",
    "            !curl.exe --output $distination_path --url $url\n",
    "        else:\n",
    "            raise Exception('Please, select a valid Operating System (i.e., Windows, macOS or Linux)')\n",
    "\n",
    "    except Exception as e:    \n",
    "        raise Exception('Something went wrong downloading the data!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import images and labels from the MNIST database\n",
    "(train_X, train_y), (test_X, test_y) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data dimensions\n",
    "print('Training images dimensions:', train_X.shape)\n",
    "print('Training labels size:', train_y.shape[0])\n",
    "print('Test images dimensions:', test_X.shape)\n",
    "print('Test labels size:', test_y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pictures in the grid\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Set up matplotlib fig\n",
    "longitude_image = 3 # Inches per picture\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * longitude_image, nrows * longitude_image)\n",
    "\n",
    "# Plot some examples\n",
    "for i in range(nrows*ncols):  \n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "    plt.imshow(train_X[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title('This is a ' + str(train_y[i]))\n",
    "\n",
    "# Plot grid\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import images and labels from the MNIST database\n",
    "(train_X, train_y), (test_X, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Shuffle train data\n",
    "permut = np.random.permutation(train_X.shape[0])\n",
    "train_X = train_X[permut]\n",
    "train_y = train_y[permut]\n",
    "\n",
    "# Shuffle test data\n",
    "permut = np.random.permutation(test_X.shape[0])\n",
    "test_X = test_X[permut]\n",
    "test_y = test_y[permut]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images to include the channels\n",
    "train_X = train_X.reshape(train_X.shape + (1,))\n",
    "test_X = test_X.reshape(test_X.shape + (1,))\n",
    "\n",
    "# Describe data dimensions\n",
    "print('Training images dimensions:', train_X.shape)\n",
    "print('Test images dimensions:', test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    "# train_X = train_X.astype('float32')\n",
    "# test_X = test_X.astype('float32')                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Labels to one hot encoded format\n",
    "train_y_one_hot = to_categorical(train_y)\n",
    "test_y_one_hot = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_X, \n",
    "                                                  train_y_one_hot, \n",
    "                                                  test_size=0.05, \n",
    "                                                  random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data dimensions\n",
    "print('Training images dimensions:', X_train.shape)\n",
    "print('Training labels size:', y_train.shape[0])\n",
    "print('Validation images dimensions:', X_val.shape)\n",
    "print('Validation labels size:', y_val.shape[0])\n",
    "print('Test images dimensions:', test_X.shape)\n",
    "print('Test labels size:', test_y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convolutional NN\n",
    "The \"output shape\" column in the summary shows how the size of your feature map evolves in each successive layer. The convolution layers reduce the size of the feature maps by a bit due to padding, and each pooling layer halves the dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LeNet-5 architecture\n",
    "lenet_5_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print summary\n",
    "lenet_5_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "lenet_5_model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for random functions\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# Fit the model\n",
    "history = lenet_5_model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=25,\n",
    "    verbose=2,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "lenet_5_model.save_weights('./model/wieghts_lenet_5.h5')\n",
    "lenet_5_model.save('./model/digit_recognizer_lenet_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating Accuracy and Loss for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics on training and test data\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc)) \n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pictures in the grid\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Set up matplotlib fig\n",
    "longitude_image = 3 # Inches per picture\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * longitude_image, nrows * longitude_image)\n",
    "\n",
    "# Plot some examples\n",
    "for i in range(nrows*ncols):\n",
    "    # Pre-process image\n",
    "    x = test_X[i].reshape((1,) + test_X[i].shape)\n",
    "    # Predict\n",
    "    classes = lenet_5_model.predict(x)\n",
    "    certainty = str(np.max(classes*100).round(1)) + '%'\n",
    "    prediction = np.argmax(classes, axis=1)\n",
    "    # Plot image\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "    plt.imshow(test_X[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title('This is a ' + str(prediction[0]) + ' [' + certainty + ']')\n",
    "\n",
    "# Plot grid\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with images to test\n",
    "use_case_path = './data/use_case'\n",
    "\n",
    "# Get names of pictures\n",
    "use_case_names = os.listdir(use_case_path)\n",
    "\n",
    "# Number of pictures in the grid\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Set up matplotlib fig\n",
    "longitude_image = 3 # Inches per picture\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * longitude_image, nrows * longitude_image)\n",
    "\n",
    "# Get path to each image\n",
    "use_case_pix = [os.path.join(use_case_path, fname) for fname in use_case_names[:nrows*ncols]]\n",
    "\n",
    "# Plot some examples\n",
    "for i, img_path in enumerate(use_case_pix):\n",
    "    # Load image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(28, 28), grayscale=True)\n",
    "    # Pre-process image\n",
    "    input_img = keras.preprocessing.image.img_to_array(img)\n",
    "    input_img = input_img / 255.\n",
    "    input_img = input_img.reshape((1,) + input_img.shape)\n",
    "    # Predict\n",
    "    classes = lenet_5_model.predict(input_img)\n",
    "    certainty = str(np.max(classes*100).round(1)) + '%'\n",
    "    prediction = np.argmax(classes, axis=1)\n",
    "    # Plot image\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    plt.title('This is a ' + str(prediction[0]) + ' [' + certainty + ']')\n",
    "\n",
    "# Plot grid\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time when finished\n",
    "now = datetime.now()\n",
    "print(\"Finished! At\", now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "class ImageGenerator:\n",
    "    def __init__(self,parent,posx,posy,*kwargs):\n",
    "        self.parent = parent\n",
    "        self.posx = posx\n",
    "        self.posy = posy\n",
    "        self.sizex = 500\n",
    "        self.sizey = 500\n",
    "        self.b1 = \"up\"\n",
    "        self.xold = None\n",
    "        self.yold = None \n",
    "        self.drawing_area=tk.Canvas(self.parent,width=self.sizex,height=self.sizey)\n",
    "        self.drawing_area.place(x=self.posx,y=self.posy)\n",
    "        self.drawing_area.bind(\"<Motion>\", self.motion)\n",
    "        self.drawing_area.bind(\"<ButtonPress-1>\", self.b1down)\n",
    "        self.drawing_area.bind(\"<ButtonRelease-1>\", self.b1up)\n",
    "        self.button=tk.Button(self.parent,text=\"Done!\",width=10,bg='white',command=self.save)\n",
    "        self.button.place(x=self.sizex/7,y=self.sizey+20)\n",
    "        self.button1=tk.Button(self.parent,text=\"Clear!\",width=10,bg='white',command=self.clear)\n",
    "        self.button1.place(x=(self.sizex/7)+80,y=self.sizey+20)\n",
    "\n",
    "        self.image=Image.new(\"RGB\",(200,200),(0,0,0))\n",
    "        self.draw=ImageDraw.Draw(self.image)\n",
    "\n",
    "    def save(self):\n",
    "        use_case_path = './data/use_case'\n",
    "        filename = './data/use_case/test.png'\n",
    "        self.image.save(filename)\n",
    "\n",
    "    def clear(self):\n",
    "        self.drawing_area.delete(\"all\")\n",
    "        self.image=Image.new(\"RGB\",(200,200),(0,0,0))\n",
    "        self.draw=ImageDraw.Draw(self.image)\n",
    "\n",
    "    def b1down(self,event):\n",
    "        self.b1 = \"down\"\n",
    "\n",
    "    def b1up(self,event):\n",
    "        self.b1 = \"up\"\n",
    "        self.xold = None\n",
    "        self.yold = None\n",
    "\n",
    "    def motion(self,event):\n",
    "        if self.b1 == \"down\":\n",
    "            if self.xold is not None and self.yold is not None:\n",
    "                event.widget.create_line(self.xold,self.yold,event.x,event.y,smooth='true',width=3,fill='white')\n",
    "                self.draw.line(((self.xold,self.yold),(event.x,event.y)),(0,128,0),width=3)\n",
    "\n",
    "        self.xold = event.x\n",
    "        self.yold = event.y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root=tk.Tk()\n",
    "    root.wm_geometry(\"%dx%d+%d+%d\" % (400, 400, 10, 10))\n",
    "    root.config(bg='black')\n",
    "    ImageGenerator(root,10,10)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "def save():\n",
    "    global image_number\n",
    "    filename = f'image_{image_number}.png'   # image_number increments by 1 at every save\n",
    "    image1.save('./data/use_case/' + filename)\n",
    "    image_number += 1\n",
    "    \n",
    "def clear():\n",
    "    cv.delete(\"all\")\n",
    "    #for item in cv.find_all():\n",
    "    #    cv.delete(item)\n",
    "\n",
    "\n",
    "def activate_paint(e):\n",
    "    global lastx, lasty\n",
    "    cv.bind('<B1-Motion>', paint)\n",
    "    lastx, lasty = e.x, e.y\n",
    "\n",
    "\n",
    "def paint(e):\n",
    "    global lastx, lasty\n",
    "    x, y = e.x, e.y\n",
    "    cv.create_line((lastx, lasty, x, y), width=1)\n",
    "    #  --- PIL\n",
    "    draw.line((lastx, lasty, x, y), fill='black', width=1)\n",
    "    lastx, lasty = x, y\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "lastx, lasty = None, None\n",
    "image_number = 0\n",
    "\n",
    "cv = Canvas(root, width=640, height=480, bg='white')\n",
    "# --- PIL\n",
    "image1 = PIL.Image.new('RGB', (640, 480), 'white')\n",
    "draw = ImageDraw.Draw(image1)\n",
    "\n",
    "cv.bind('<1>', activate_paint)\n",
    "cv.pack(expand=YES, fill=BOTH)\n",
    "\n",
    "btn_save = Button(text=\"Save\", command=save)\n",
    "btn_save.pack()\n",
    "btn_save = Button(text=\"Clear\", command=clear)\n",
    "btn_save.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digit_recognition-TF-GPU-2.4.0",
   "language": "python",
   "name": "digit_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
